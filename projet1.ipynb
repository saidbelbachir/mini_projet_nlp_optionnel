{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "43e33cd7",
   "metadata": {},
   "source": [
    "## Installer les bibliothÃ¨ques"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "05b2bc57",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: transformers in c:\\users\\said\\anaconda3\\lib\\site-packages (2.5.1)\n",
      "Requirement already satisfied: filelock in c:\\users\\said\\anaconda3\\lib\\site-packages (from transformers) (3.0.12)\n",
      "Requirement already satisfied: tqdm>=4.27 in c:\\users\\said\\anaconda3\\lib\\site-packages (from transformers) (4.59.0)\n",
      "Requirement already satisfied: numpy in c:\\users\\said\\anaconda3\\lib\\site-packages (from transformers) (1.18.5)\n",
      "Requirement already satisfied: regex!=2019.12.17 in c:\\users\\said\\anaconda3\\lib\\site-packages (from transformers) (2021.4.4)\n",
      "Requirement already satisfied: tokenizers==0.5.2 in c:\\users\\said\\anaconda3\\lib\\site-packages (from transformers) (0.5.2)\n",
      "Requirement already satisfied: sentencepiece in c:\\users\\said\\anaconda3\\lib\\site-packages (from transformers) (0.1.96)\n",
      "Requirement already satisfied: requests in c:\\users\\said\\anaconda3\\lib\\site-packages (from transformers) (2.25.1)\n",
      "Requirement already satisfied: sacremoses in c:\\users\\said\\anaconda3\\lib\\site-packages (from transformers) (0.0.45)\n",
      "Requirement already satisfied: boto3 in c:\\users\\said\\anaconda3\\lib\\site-packages (from transformers) (1.18.33)\n",
      "Requirement already satisfied: s3transfer<0.6.0,>=0.5.0 in c:\\users\\said\\anaconda3\\lib\\site-packages (from boto3->transformers) (0.5.0)\n",
      "Requirement already satisfied: jmespath<1.0.0,>=0.7.1 in c:\\users\\said\\anaconda3\\lib\\site-packages (from boto3->transformers) (0.10.0)\n",
      "Requirement already satisfied: botocore<1.22.0,>=1.21.33 in c:\\users\\said\\anaconda3\\lib\\site-packages (from boto3->transformers) (1.21.33)\n",
      "Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in c:\\users\\said\\anaconda3\\lib\\site-packages (from botocore<1.22.0,>=1.21.33->boto3->transformers) (2.8.1)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.25.4 in c:\\users\\said\\anaconda3\\lib\\site-packages (from botocore<1.22.0,>=1.21.33->boto3->transformers) (1.26.4)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\said\\anaconda3\\lib\\site-packages (from python-dateutil<3.0.0,>=2.1->botocore<1.22.0,>=1.21.33->boto3->transformers) (1.15.0)\n",
      "Requirement already satisfied: idna<3,>=2.5 in c:\\users\\said\\anaconda3\\lib\\site-packages (from requests->transformers) (2.10)\n",
      "Requirement already satisfied: chardet<5,>=3.0.2 in c:\\users\\said\\anaconda3\\lib\\site-packages (from requests->transformers) (4.0.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\said\\anaconda3\\lib\\site-packages (from requests->transformers) (2020.12.5)\n",
      "Requirement already satisfied: click in c:\\users\\said\\anaconda3\\lib\\site-packages (from sacremoses->transformers) (7.1.2)\n",
      "Requirement already satisfied: joblib in c:\\users\\said\\anaconda3\\lib\\site-packages (from sacremoses->transformers) (1.0.1)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3775f3d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in links: https://download.pytorch.org/whl/torch_stable.htmlNote: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: torch==1.4.0+cpu in c:\\users\\said\\anaconda3\\lib\\site-packages (1.4.0+cpu)\n",
      "Requirement already satisfied: torchvision==0.5.0+cpu in c:\\users\\said\\anaconda3\\lib\\site-packages (0.5.0+cpu)\n",
      "Requirement already satisfied: numpy in c:\\users\\said\\anaconda3\\lib\\site-packages (from torchvision==0.5.0+cpu) (1.18.5)\n",
      "Requirement already satisfied: pillow>=4.1.1 in c:\\users\\said\\anaconda3\\lib\\site-packages (from torchvision==0.5.0+cpu) (8.2.0)\n",
      "Requirement already satisfied: six in c:\\users\\said\\anaconda3\\lib\\site-packages (from torchvision==0.5.0+cpu) (1.15.0)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "pip install torch==1.4.0+cpu torchvision==0.5.0+cpu -f https://download.pytorch.org/whl/torch_stable.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5fa890be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: transformers in c:\\users\\said\\anaconda3\\lib\\site-packages (2.5.1)Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "spacy-transformers 0.6.0 requires transformers<2.6.0,>=2.4.0, but you have transformers 4.10.0 which is incompatible.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Collecting transformers\n",
      "  Using cached transformers-4.10.0-py3-none-any.whl (2.8 MB)\n",
      "Requirement already satisfied: requests in c:\\users\\said\\anaconda3\\lib\\site-packages (from transformers) (2.25.1)\n",
      "Collecting tokenizers<0.11,>=0.10.1\n",
      "  Using cached tokenizers-0.10.3-cp38-cp38-win_amd64.whl (2.0 MB)\n",
      "Requirement already satisfied: huggingface-hub>=0.0.12 in c:\\users\\said\\anaconda3\\lib\\site-packages (from transformers) (0.0.16)\n",
      "Requirement already satisfied: filelock in c:\\users\\said\\anaconda3\\lib\\site-packages (from transformers) (3.0.12)\n",
      "Requirement already satisfied: sacremoses in c:\\users\\said\\anaconda3\\lib\\site-packages (from transformers) (0.0.45)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\said\\anaconda3\\lib\\site-packages (from transformers) (5.4.1)\n",
      "Requirement already satisfied: tqdm>=4.27 in c:\\users\\said\\anaconda3\\lib\\site-packages (from transformers) (4.59.0)\n",
      "Requirement already satisfied: regex!=2019.12.17 in c:\\users\\said\\anaconda3\\lib\\site-packages (from transformers) (2021.4.4)\n",
      "Requirement already satisfied: packaging in c:\\users\\said\\anaconda3\\lib\\site-packages (from transformers) (20.9)\n",
      "Requirement already satisfied: numpy>=1.17 in c:\\users\\said\\anaconda3\\lib\\site-packages (from transformers) (1.18.5)\n",
      "Requirement already satisfied: typing-extensions in c:\\users\\said\\anaconda3\\lib\\site-packages (from huggingface-hub>=0.0.12->transformers) (3.7.4.3)\n",
      "Requirement already satisfied: pyparsing>=2.0.2 in c:\\users\\said\\anaconda3\\lib\\site-packages (from packaging->transformers) (2.4.7)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\said\\anaconda3\\lib\\site-packages (from requests->transformers) (2020.12.5)\n",
      "Requirement already satisfied: chardet<5,>=3.0.2 in c:\\users\\said\\anaconda3\\lib\\site-packages (from requests->transformers) (4.0.0)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\said\\anaconda3\\lib\\site-packages (from requests->transformers) (1.26.4)\n",
      "Requirement already satisfied: idna<3,>=2.5 in c:\\users\\said\\anaconda3\\lib\\site-packages (from requests->transformers) (2.10)\n",
      "Requirement already satisfied: click in c:\\users\\said\\anaconda3\\lib\\site-packages (from sacremoses->transformers) (7.1.2)\n",
      "Requirement already satisfied: joblib in c:\\users\\said\\anaconda3\\lib\\site-packages (from sacremoses->transformers) (1.0.1)\n",
      "Requirement already satisfied: six in c:\\users\\said\\anaconda3\\lib\\site-packages (from sacremoses->transformers) (1.15.0)\n",
      "Installing collected packages: tokenizers, transformers\n",
      "  Attempting uninstall: tokenizers\n",
      "    Found existing installation: tokenizers 0.5.2\n",
      "    Uninstalling tokenizers-0.5.2:\n",
      "      Successfully uninstalled tokenizers-0.5.2\n",
      "  Attempting uninstall: transformers\n",
      "    Found existing installation: transformers 2.5.1\n",
      "    Uninstalling transformers-2.5.1:\n",
      "      Successfully uninstalled transformers-2.5.1\n",
      "Successfully installed tokenizers-0.10.3 transformers-4.10.0\n"
     ]
    }
   ],
   "source": [
    "pip install transformers -U"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ad768432",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in links: https://download.pytorch.org/whl/torch_stable.html\n",
      "Requirement already satisfied: torch in c:\\users\\said\\anaconda3\\lib\\site-packages (1.4.0+cpu)\n",
      "Requirement already satisfied: torchvision in c:\\users\\said\\anaconda3\\lib\\site-packages (0.5.0+cpu)\n",
      "Requirement already satisfied: six in c:\\users\\said\\anaconda3\\lib\\site-packages (from torchvision) (1.15.0)\n",
      "Requirement already satisfied: numpy in c:\\users\\said\\anaconda3\\lib\\site-packages (from torchvision) (1.18.5)\n",
      "Requirement already satisfied: pillow>=4.1.1 in c:\\users\\said\\anaconda3\\lib\\site-packages (from torchvision) (8.2.0)\n",
      "Collecting transformers==2.5.1\n",
      "  Using cached transformers-2.5.1-py3-none-any.whl (499 kB)\n",
      "Requirement already satisfied: requests in c:\\users\\said\\anaconda3\\lib\\site-packages (from transformers==2.5.1) (2.25.1)\n",
      "Requirement already satisfied: regex!=2019.12.17 in c:\\users\\said\\anaconda3\\lib\\site-packages (from transformers==2.5.1) (2021.4.4)\n",
      "Requirement already satisfied: sacremoses in c:\\users\\said\\anaconda3\\lib\\site-packages (from transformers==2.5.1) (0.0.45)\n",
      "Collecting tokenizers==0.5.2\n",
      "  Using cached tokenizers-0.5.2-cp38-cp38-win_amd64.whl (1.0 MB)\n",
      "Requirement already satisfied: boto3 in c:\\users\\said\\anaconda3\\lib\\site-packages (from transformers==2.5.1) (1.18.33)\n",
      "Requirement already satisfied: numpy in c:\\users\\said\\anaconda3\\lib\\site-packages (from transformers==2.5.1) (1.18.5)\n",
      "Requirement already satisfied: filelock in c:\\users\\said\\anaconda3\\lib\\site-packages (from transformers==2.5.1) (3.0.12)\n",
      "Requirement already satisfied: sentencepiece in c:\\users\\said\\anaconda3\\lib\\site-packages (from transformers==2.5.1) (0.1.96)\n",
      "Requirement already satisfied: tqdm>=4.27 in c:\\users\\said\\anaconda3\\lib\\site-packages (from transformers==2.5.1) (4.59.0)\n",
      "Requirement already satisfied: s3transfer<0.6.0,>=0.5.0 in c:\\users\\said\\anaconda3\\lib\\site-packages (from boto3->transformers==2.5.1) (0.5.0)\n",
      "Requirement already satisfied: jmespath<1.0.0,>=0.7.1 in c:\\users\\said\\anaconda3\\lib\\site-packages (from boto3->transformers==2.5.1) (0.10.0)\n",
      "Requirement already satisfied: botocore<1.22.0,>=1.21.33 in c:\\users\\said\\anaconda3\\lib\\site-packages (from boto3->transformers==2.5.1) (1.21.33)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.25.4 in c:\\users\\said\\anaconda3\\lib\\site-packages (from botocore<1.22.0,>=1.21.33->boto3->transformers==2.5.1) (1.26.4)\n",
      "Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in c:\\users\\said\\anaconda3\\lib\\site-packages (from botocore<1.22.0,>=1.21.33->boto3->transformers==2.5.1) (2.8.1)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\said\\anaconda3\\lib\\site-packages (from python-dateutil<3.0.0,>=2.1->botocore<1.22.0,>=1.21.33->boto3->transformers==2.5.1) (1.15.0)\n",
      "Requirement already satisfied: chardet<5,>=3.0.2 in c:\\users\\said\\anaconda3\\lib\\site-packages (from requests->transformers==2.5.1) (4.0.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\said\\anaconda3\\lib\\site-packages (from requests->transformers==2.5.1) (2020.12.5)\n",
      "Requirement already satisfied: idna<3,>=2.5 in c:\\users\\said\\anaconda3\\lib\\site-packages (from requests->transformers==2.5.1) (2.10)\n",
      "Requirement already satisfied: joblib in c:\\users\\said\\anaconda3\\lib\\site-packages (from sacremoses->transformers==2.5.1) (1.0.1)\n",
      "Requirement already satisfied: click in c:\\users\\said\\anaconda3\\lib\\site-packages (from sacremoses->transformers==2.5.1) (7.1.2)\n",
      "Installing collected packages: tokenizers, transformers\n",
      "  Attempting uninstall: tokenizers\n",
      "    Found existing installation: tokenizers 0.10.3\n",
      "    Uninstalling tokenizers-0.10.3:\n",
      "      Successfully uninstalled tokenizers-0.10.3\n",
      "  Attempting uninstall: transformers\n",
      "    Found existing installation: transformers 4.10.0\n",
      "    Uninstalling transformers-4.10.0:\n",
      "      Successfully uninstalled transformers-4.10.0\n",
      "Successfully installed tokenizers-0.5.2 transformers-2.5.1\n",
      "Requirement already satisfied: wikipedia==1.4.0 in c:\\users\\said\\anaconda3\\lib\\site-packages (1.4.0)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.0.0 in c:\\users\\said\\anaconda3\\lib\\site-packages (from wikipedia==1.4.0) (2.25.1)\n",
      "Requirement already satisfied: beautifulsoup4 in c:\\users\\said\\anaconda3\\lib\\site-packages (from wikipedia==1.4.0) (4.9.3)\n",
      "Requirement already satisfied: chardet<5,>=3.0.2 in c:\\users\\said\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.0.0->wikipedia==1.4.0) (4.0.0)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\said\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.0.0->wikipedia==1.4.0) (1.26.4)\n",
      "Requirement already satisfied: idna<3,>=2.5 in c:\\users\\said\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.0.0->wikipedia==1.4.0) (2.10)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\said\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.0.0->wikipedia==1.4.0) (2020.12.5)\n",
      "Requirement already satisfied: soupsieve>1.2 in c:\\users\\said\\anaconda3\\lib\\site-packages (from beautifulsoup4->wikipedia==1.4.0) (2.2.1)\n"
     ]
    }
   ],
   "source": [
    "!pip install torch  torchvision -f https://download.pytorch.org/whl/torch_stable.html\n",
    "    \n",
    "!pip install transformers==2.5.1\n",
    "\n",
    "!pip install wikipedia==1.4.0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c26080a3",
   "metadata": {},
   "source": [
    "## importer les bibliothÃ¨ques"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cdbd6539",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "840378c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import BertForQuestionAnswering"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f70a1592",
   "metadata": {},
   "source": [
    "## vÃ©rifier les bibliothÃ¨ques"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "13856b30",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.4.0+cpu\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "print(torch.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f3177098",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.5720, 0.1947, 0.0103],\n",
      "        [0.1401, 0.1536, 0.6070],\n",
      "        [0.7467, 0.2615, 0.8293],\n",
      "        [0.3689, 0.6648, 0.5965],\n",
      "        [0.1803, 0.0113, 0.2615]])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "print(torch.rand(5, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "bbab4e0c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ada2cfc7",
   "metadata": {},
   "source": [
    "## Construire le pipeline de rÃ©ponses aux questions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "59e5ebb6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0507654f54e44420ad9ca0ff79d63db2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/411 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a4c0b0bb571b4679b48732191e0fabfe",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/213k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "063adb4de414484883786a5297ca8d25",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/230 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4d09a197348c495b87c286cc40e07e3a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/473 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2ff022a289e947aabb3592a5dfc6d766",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/261M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "question_answering = pipeline(\"question-answering\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02a21a16",
   "metadata": {},
   "source": [
    "## DÃ©finir le contexte et la question Ã  poser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a54ec3c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "context = \"\"\"\n",
    "Machine learning (ML) is the study of computer algorithms that improve automatically through experience. It is seen as a part of artificial intelligence. Machine learning algorithms build a model based on sample data, known as \"training data\", in order to make predictions or decisions without being explicitly programmed to do so. Machine learning algorithms are used in a wide variety of applications, such as email filtering and computer vision, where it is difficult or unfeasible to develop conventional algorithms to perform the needed tasks.\n",
    "\"\"\"\n",
    "\n",
    "question = \"What are machine learning models based on?\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "856905be",
   "metadata": {},
   "source": [
    "## Effectuer une rÃ©ponse aux questions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2838df72",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "convert squad examples to features: 100%|ââââââââââ| 1/1 [00:00<00:00, 27.78it/s]\n",
      "add example index and unique id: 100%|ââââââââââ| 1/1 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer: sample data,\n",
      "Score: 0.8846622120498289\n"
     ]
    }
   ],
   "source": [
    "result = question_answering(question=question, context=context)\n",
    "print(\"Answer:\", result['answer'])\n",
    "print(\"Score:\", result['score'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1daf95ee",
   "metadata": {},
   "source": [
    "## RÃ©ponse aux questions pour n'importe quelle langue"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3421f18a",
   "metadata": {},
   "source": [
    "# langue arabe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3ab3467e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1669bbaf4a2b4989ae0b2dd50f3ef782",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/657 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e0fbd7019fda49ac8404d0382b1d8d87",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/996k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cbc123a6794346a08cef51b435001840",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/112 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "03e0b0add8c643098b9de9bd10e31a54",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/40.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model name 'mrm8488/bert-multi-cased-finetuned-xquadv1' was not found in model name list (bert-base-uncased, bert-large-uncased, bert-base-cased, bert-large-cased, bert-base-multilingual-uncased, bert-base-multilingual-cased, bert-base-chinese, bert-base-german-cased, bert-large-uncased-whole-word-masking, bert-large-cased-whole-word-masking, bert-large-uncased-whole-word-masking-finetuned-squad, bert-large-cased-whole-word-masking-finetuned-squad, bert-base-cased-finetuned-mrpc, bert-base-german-dbmdz-cased, bert-base-german-dbmdz-uncased, bert-base-japanese, bert-base-japanese-whole-word-masking, bert-base-japanese-char, bert-base-japanese-char-whole-word-masking, bert-base-finnish-cased-v1, bert-base-finnish-uncased-v1, bert-base-dutch-cased, bart-large, bart-large-mnli, bart-cnn, openai-gpt, transfo-xl-wt103, gpt2, gpt2-medium, gpt2-large, gpt2-xl, distilgpt2, ctrl, xlnet-base-cased, xlnet-large-cased, xlm-mlm-en-2048, xlm-mlm-ende-1024, xlm-mlm-enfr-1024, xlm-mlm-enro-1024, xlm-mlm-tlm-xnli15-1024, xlm-mlm-xnli15-1024, xlm-clm-enfr-1024, xlm-clm-ende-1024, xlm-mlm-17-1280, xlm-mlm-100-1280, roberta-base, roberta-large, roberta-large-mnli, distilroberta-base, roberta-base-openai-detector, roberta-large-openai-detector, distilbert-base-uncased, distilbert-base-uncased-distilled-squad, distilbert-base-cased, distilbert-base-cased-distilled-squad, distilbert-base-german-cased, distilbert-base-multilingual-cased, distilbert-base-uncased-finetuned-sst-2-english, albert-base-v1, albert-large-v1, albert-xlarge-v1, albert-xxlarge-v1, albert-base-v2, albert-large-v2, albert-xlarge-v2, albert-xxlarge-v2, camembert-base, umberto-commoncrawl-cased-v1, umberto-wikipedia-uncased-v1, t5-small, t5-base, t5-large, t5-3b, t5-11b, xlm-roberta-base, xlm-roberta-large, xlm-roberta-large-finetuned-conll02-dutch, xlm-roberta-large-finetuned-conll02-spanish, xlm-roberta-large-finetuned-conll03-english, xlm-roberta-large-finetuned-conll03-german, flaubert-small-cased, flaubert-base-uncased, flaubert-base-cased, flaubert-large-cased). We assumed 'https://s3.amazonaws.com/models.huggingface.co/bert/mrm8488/bert-multi-cased-finetuned-xquadv1/modelcard.json' was a path or url to a model card file named modelcard.json or a directory containing such a file but couldn't find any such file at this path or url.\n",
      "Creating an empty model card.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4a7035d867594c23a81901ccf117f6d1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/711M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "convert squad examples to features: 100%|ââââââââââ| 1/1 [00:00<00:00, 130.84it/s]\n",
      "add example index and unique id: 100%|ââââââââââ| 1/1 [00:00<00:00, 1000.31it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer: ÙØ§ Ø¨Ø§ÙÙØ³ÙÙ\n",
      "Score: 0.28314340374556224\n"
     ]
    }
   ],
   "source": [
    "question_answering = pipeline(\"question-answering\", model=\"mrm8488/bert-multi-cased-finetuned-xquadv1\",\n",
    "    tokenizer=\"mrm8488/bert-multi-cased-finetuned-xquadv1\")\n",
    "\n",
    "\n",
    "\n",
    "context = \"\"\"Ø£Ù Ø§ÙÙÙ ÙØ§ ÙØºÙØ± ÙØ§ Ø¨ÙÙÙ Ø­ØªÙ ÙØºÙØ±ÙØ§ ÙØ§ Ø¨Ø§ÙÙØ³ÙÙ\"\"\"\n",
    "\n",
    "question = \"ÙØ§Ø°Ø§ Ø³ÙØªØºÙØ±Ø\"\n",
    "\n",
    "result = question_answering(question=question, context=context)\n",
    "print(\"Answer:\", result['answer'])\n",
    "print(\"Score:\", result['score'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bfff186",
   "metadata": {},
   "source": [
    "# langue franÃ§aise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3eb89ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model name 'mrm8488/bert-multi-cased-finetuned-xquadv1' was not found in model name list (bert-base-uncased, bert-large-uncased, bert-base-cased, bert-large-cased, bert-base-multilingual-uncased, bert-base-multilingual-cased, bert-base-chinese, bert-base-german-cased, bert-large-uncased-whole-word-masking, bert-large-cased-whole-word-masking, bert-large-uncased-whole-word-masking-finetuned-squad, bert-large-cased-whole-word-masking-finetuned-squad, bert-base-cased-finetuned-mrpc, bert-base-german-dbmdz-cased, bert-base-german-dbmdz-uncased, bert-base-japanese, bert-base-japanese-whole-word-masking, bert-base-japanese-char, bert-base-japanese-char-whole-word-masking, bert-base-finnish-cased-v1, bert-base-finnish-uncased-v1, bert-base-dutch-cased, bart-large, bart-large-mnli, bart-cnn, openai-gpt, transfo-xl-wt103, gpt2, gpt2-medium, gpt2-large, gpt2-xl, distilgpt2, ctrl, xlnet-base-cased, xlnet-large-cased, xlm-mlm-en-2048, xlm-mlm-ende-1024, xlm-mlm-enfr-1024, xlm-mlm-enro-1024, xlm-mlm-tlm-xnli15-1024, xlm-mlm-xnli15-1024, xlm-clm-enfr-1024, xlm-clm-ende-1024, xlm-mlm-17-1280, xlm-mlm-100-1280, roberta-base, roberta-large, roberta-large-mnli, distilroberta-base, roberta-base-openai-detector, roberta-large-openai-detector, distilbert-base-uncased, distilbert-base-uncased-distilled-squad, distilbert-base-cased, distilbert-base-cased-distilled-squad, distilbert-base-german-cased, distilbert-base-multilingual-cased, distilbert-base-uncased-finetuned-sst-2-english, albert-base-v1, albert-large-v1, albert-xlarge-v1, albert-xxlarge-v1, albert-base-v2, albert-large-v2, albert-xlarge-v2, albert-xxlarge-v2, camembert-base, umberto-commoncrawl-cased-v1, umberto-wikipedia-uncased-v1, t5-small, t5-base, t5-large, t5-3b, t5-11b, xlm-roberta-base, xlm-roberta-large, xlm-roberta-large-finetuned-conll02-dutch, xlm-roberta-large-finetuned-conll02-spanish, xlm-roberta-large-finetuned-conll03-english, xlm-roberta-large-finetuned-conll03-german, flaubert-small-cased, flaubert-base-uncased, flaubert-base-cased, flaubert-large-cased). We assumed 'https://s3.amazonaws.com/models.huggingface.co/bert/mrm8488/bert-multi-cased-finetuned-xquadv1/modelcard.json' was a path or url to a model card file named modelcard.json or a directory containing such a file but couldn't find any such file at this path or url.\n",
      "Creating an empty model card.\n"
     ]
    }
   ],
   "source": [
    "question_answering = pipeline(\"question-answering\", model=\"mrm8488/bert-multi-cased-finetuned-xquadv1\",\n",
    "    tokenizer=\"mrm8488/bert-multi-cased-finetuned-xquadv1\")\n",
    "\n",
    "\n",
    "\n",
    "context = \"\"\"Edson Arantes do Nascimento2,3, dit PelÃ©, ONM â¢ ORB â¢ KBE, nÃ© le 23 octobre 1940 Ã  TrÃªs CoraÃ§Ãµes (BrÃ©sil, Ãtat du Minas Gerais), est un footballeur brÃ©silien Ã©voluant au poste d'attaquant et de meneur de jeu du milieu des annÃ©es 1950 au milieu des annÃ©es 1970. Il est Ã©galement acteur, scÃ©nariste et producteur.\n",
    "\n",
    "Figure majeure du football qui est considÃ©rÃ© comme le plus grand joueur de l'histoire 4, il est le seul footballeur Ã  avoir Ã©tÃ© champion du monde Ã  trois reprises, en 1958, 1962 et 1970, avec la sÃ©lection brÃ©silienne. Il compte Ã©galement un palmarÃ¨s exceptionnel avec les deux clubs professionnels qu'il a connus (Santos FC et New York Cosmos) dont la Coupe intercontinentale (1962 et 1963), la Copa Libertadores (1962 et 1963), le championnat des Ãtats-Unis (1977) et, Ã  onze reprises, le championnat de SÃ£o Paulo dans les annÃ©es 1950 et 1960 mais Ã©galement plusieurs rÃ©compenses individuelles comme le prix d'athlÃ¨te du siÃ¨cle par le CIO, joueur du XXe siÃ¨cle par la FIFA et le ballon d'Or d'honneur le 13 janvier 20145. Il fait partie de l'Ã©quipe mondiale du xxe siÃ¨cle.\n",
    "\n",
    "Son conseiller technique se nommait Â« Stef Cohen Â»\n",
    "\n",
    "Depuis sa retraite sportive, PelÃ© est l'ambassadeur pour l'ONU et l'UNESCO Ã  l'Ãducation, l'Ãcologie et l'Environnement. Il continue Ã©galement Ã  prÃªter son image Ã  diverses entreprises et a occupÃ© le poste de ministre des Sports du BrÃ©sil entre 1995 et 1998. Pour autant, il n'a pas quittÃ© le monde du football puisqu'il a Ã©tÃ© l'ambassadeur international de la Coupe du monde de 2014 qui s'est dÃ©roulÃ©e au BrÃ©sil. En 2011, il est nommÃ© par Paul Kemsley (en) prÃ©sident d'honneur du Cosmos de New York, son ancien club Ã  New York, mais la franchise peine Ã  offrir un projet convaincant pour intÃ©grer la Major League Soccer, ce qui aboutit Ã  un Ã©chec.\n",
    "\n",
    "En 2021, avec MÃ¡rio Zagallo, il est le dernier survivant des joueurs brÃ©siliens ayant disputÃ© la finale de 1958.\"\"\"\n",
    "\n",
    "question = \"quel age a PelÃ© ?\"\n",
    "\n",
    "\n",
    "result = question_answering(question=question, context=context)\n",
    "print(\"Answer:\", result['answer'])\n",
    "print(\"Score:\", result['score'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6dd5375e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
